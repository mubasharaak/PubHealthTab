{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152b22b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import dns\n",
    "import dnspython\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import multiprocessing\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pymongo\n",
    "import random\n",
    "import re\n",
    "import requests\n",
    "import requests.exceptions\n",
    "import scispacy\n",
    "import spacy\n",
    "# import spacy_transformers\n",
    "\n",
    "from datetime import date\n",
    "from nltk import tokenize\n",
    "from pathlib import Path\n",
    "from requests_futures.sessions import *\n",
    "\n",
    "from scispacy.abbreviation import AbbreviationDetector\n",
    "from scispacy.linking import EntityLinker\n",
    "from sklearn.metrics import matthews_corrcoef, f1_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "from typing import Dict\n",
    "from urllib.parse import urlsplit\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from string import punctuation\n",
    "\n",
    "#nltk.download('punkt')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f61850",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('claim_filtering')\n",
    "logger.setLevel(logging.INFO)\n",
    "pd.set_option(\"max_colwidth\", 100)\n",
    "pd.set_option(\"max_rows\", 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444f5686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MongoDB connection \n",
    "\n",
    "db_client = pymongo.MongoClient(\"...\") # Link to DB\n",
    "db = db_client.pubhealth\n",
    "train_col = db.trainset\n",
    "test_col = db.testset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927be5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load initial training and test set into mongodb \n",
    "insert_total_set = False\n",
    "\n",
    "# train_data.reset_index(inplace=True) \n",
    "if insert_total_set:\n",
    "    train_data = pd.read_csv('datasets/train.tsv', sep='\\t')\n",
    "    test_data = pd.read_csv('datasets/test.tsv', sep='\\t')\n",
    "    test_data.drop(columns=[\"Unnamed: 0\"]) if \"Unnamed: 0\" in test_data.columns else None\n",
    "\n",
    "    print(f'Train dataset contrains {len(train_data)} total entries.\\n')\n",
    "    print(f'Test dataset contrains {len(test_data)} total entries.\\n')\n",
    "    \n",
    "    print(train_data.columns)\n",
    "\n",
    "    train_col.delete_many({})\n",
    "    train_dict = train_data.to_dict(\"records\")\n",
    "    train_col.insert_many(train_dict)\n",
    "\n",
    "    test_col.delete_many({})\n",
    "    test_dict = test_data.to_dict(\"records\")\n",
    "    test_col.insert_many(test_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146fe569",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_train_set = True\n",
    "read_test_set = True\n",
    "\n",
    "if read_train_set:\n",
    "    cursor =  train_col.find({'relevant_claim': True})\n",
    "#     cursor =  train_col.find()\n",
    "    \n",
    "    train_data = pd.DataFrame(list(cursor)) \n",
    "    print(f\"Length of training set: {len(train_data)}\")\n",
    "\n",
    "if read_test_set:\n",
    "    cursor =  test_col.find({'relevant_claim': True})\n",
    "    test_data = pd.DataFrame(list(cursor)) \n",
    "    print(f\"Length of test set: {len(test_data)}\")\n",
    "\n",
    "train_data.head(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd46f6cf",
   "metadata": {},
   "source": [
    "#### Load medical corpus/entities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5139437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "med_corpus = []\n",
    "with open(r'./medical_corpus/medical_corpus.csv', 'r') as file:\n",
    "    csv_reader = csv.reader(file, delimiter=',', quoting=csv.QUOTE_ALL)\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        med_corpus.extend(row)\n",
    "    \n",
    "len(med_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206734dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_entities = []\n",
    "with open(r'./medical_corpus/medical_cn_entities.csv', 'r') as file:\n",
    "    csv_reader = csv.reader(file, delimiter=',', quoting=csv.QUOTE_ALL)\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        medical_entities.extend(row)\n",
    "\n",
    "len(medical_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d827b7e5",
   "metadata": {},
   "source": [
    "#### 1. Create and save medical corpus using corpus from Wikipedia, Harvard, UMich, Schulich \n",
    "#### 2. For each term in corpus => find entity in ConceptNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f982b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over term files and save in one list \n",
    "create_corpus = False\n",
    "\n",
    "if create_corpus:\n",
    "    med_corpus = []\n",
    "    for file in os.listdir('./medical_corpus'):\n",
    "        temp = pd.read_csv(os.path.join('./medical_corpus', file))\n",
    "        med_corpus.extend([entry.strip().lower().split(\":\")[0] for entry in temp[\"Column 1\"]])\n",
    "\n",
    "    med_corpus = list(set(med_corpus))\n",
    "    print(len(med_corpus))\n",
    "    \n",
    "    with open(r'./medical_corpus/medical_corpus.csv', 'w') as file:\n",
    "    wr = csv.writer(file, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(med_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdf7676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CN entities for claim's entities \n",
    "# If ConceptNet entry found check if context relations include keywords from med_corpus     \n",
    "\n",
    "entities_for_corpus = False \n",
    "\n",
    "if entities_for_corpus:\n",
    "    medical_entities = []\n",
    "    for term in med_corpus:\n",
    "        for cn_entity in get_conceptnet_entity(term): \n",
    "            medical_entities.append(cn_entity)\n",
    "            medical_entities.extend(get_sub_topics(cn_entity))\n",
    "\n",
    "    print(len(medical_entities))\n",
    "    with open(r'./medical_corpus/medical_cn_entities.csv', 'w') as file:\n",
    "    wr = csv.writer(file, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(medical_entities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a375822",
   "metadata": {},
   "source": [
    "## Filtering PubHealth Claims \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06c7307",
   "metadata": {},
   "source": [
    "### (1) NER with SciSpacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc61385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_sci_lg\")\n",
    "\n",
    "# Add the abbreviation pipe to the spacy pipeline.\n",
    "nlp.add_pipe(\"abbreviation_detector\")\n",
    "\n",
    "# Add umls entity linker\n",
    "nlp.add_pipe(\"scispacy_linker\", config={\"resolve_abbreviations\": True, \"linker_name\": \"umls\", \n",
    "                                        \"threshold\": 0.3, \"no_definition_threshold\": 0.6, \n",
    "                                        \"filter_for_definitions\": True, \n",
    "                                        \"max_entities_per_mention\": 15})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0646e72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(claim: str) -> list: \n",
    "    \"\"\"\n",
    "    Returns for a claim a list of recognized enitities using SciSpacy\n",
    "    \"\"\"\n",
    "    if type(claim)!=str: \n",
    "        entities = []\n",
    "    else:\n",
    "        doc = nlp(claim)    \n",
    "        entities = [entity.text for entity in doc.ents]\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93680e88",
   "metadata": {},
   "source": [
    "### (2) Extracting public health related claims (add. sources used: medical term corpus, ConceptNet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a20ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_topics(topic: str) -> list:\n",
    "    url = \"http://api.conceptnet.io/query\"\n",
    "    params = {\n",
    "        'end': topic,\n",
    "        'rel': \"/r/IsA\",\n",
    "        'limit': 10000\n",
    "    }\n",
    "    result = requests.get(url, params)\n",
    "    result = result.json()\n",
    "    topics = [edge['start']['term'] for edge in result['edges']]\n",
    "    return topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed30fcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hop_entities(cn_entity) -> list:\n",
    "    url = \"http://api.conceptnet.io/query\"\n",
    "    hop_entities = []\n",
    "    try:\n",
    "        # Type of\n",
    "        params = {\n",
    "            'start': cn_entity,\n",
    "            'rel': \"/r/IsA\",\n",
    "            'limit': 10000\n",
    "        }\n",
    "        result = requests.get(url, params).json()\n",
    "        hop_entities = [edge['end']['term'] for edge in result['edges'] if \"/c/en\" in edge['end']['term']]\n",
    "        hop_entities = list(set(hop_entities))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Following error occured while execution of function get_hop_entities: {e}.\")\n",
    "\n",
    "    return hop_entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facb20b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conceptnet_entity(entity: str):\n",
    "    result_list = []\n",
    "    entity_merged = entity.lower().strip().replace(\" \", \"_\")\n",
    "    base_url =  'http://api.conceptnet.io/c/en/'\n",
    "    url = base_url+entity_merged\n",
    "    \n",
    "    result = requests.get(url).json()\n",
    "    result_id = \"\"\n",
    "    \n",
    "    if 'error' in result:\n",
    "        print(f\"The following error occurred during execution of function 'get_conceptnet_entity': {result['error']['details']}.\")\n",
    "    else:\n",
    "        result_id = result['@id']\n",
    "        result_list.append(result_id)\n",
    "    \n",
    "    return result_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558db08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pubhealth_match(cn_entry: str, pubhealth_topics: set) -> bool:\n",
    "    \n",
    "    is_match = False\n",
    "    try:\n",
    "        url = \"http://api.conceptnet.io/query\"\n",
    "        params = {\n",
    "            'start': cn_entry,\n",
    "            'rel': \"/r/HasContext\",\n",
    "            'limit': 10000\n",
    "        }\n",
    "        req_result = requests.get(url, params)\n",
    "        if 'error' in req_result:\n",
    "            logger.info(f\"The following error occurred during execution of function 'pubhealth_match': {req_result['error']['details']}.\")\n",
    "        else:\n",
    "            result = req_result.json()\n",
    "            end_nodes = [edge['end']['term'] for edge in result['edges']]\n",
    "            if end_nodes and len(end_nodes)>0 and not set(end_nodes).isdisjoint(pubhealth_topics):\n",
    "                is_match = True\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Following error occured while execution of function pubhealth_match: {e}.\")\n",
    "            \n",
    "    return is_match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d88628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasMedicalContext_ConceptNet(input_data, med_corpus = med_corpus, med_entities = medical_entities) -> bool: \n",
    "    \"\"\"\n",
    "    Returns True if claim related to a PubHealth topic. Use ConceptNet to determine this is keyword approach not enough.\n",
    "    \n",
    "    Procedure:\n",
    "    # 1. check if medical keyword (from corpus) in claim => return true \n",
    "    # 2. Get conceptnet nodes for all medical keywords + claim's entities => med_conceptnet\n",
    "    # 3. check if claim's entities HasContext in med_entities => return true \n",
    "    # 4. check one-hop IsA node for claim's entities => HasContext in med_conceptnet? => return true \n",
    "    \n",
    "    Parameters:\n",
    "    input_data(set): set containing claim, entities linked with SciSpacy and row index\n",
    "    med_corpus(list): list of medical terms scraped from medial glossaries (Wikipedia, Harvard, UMich, Schulich)\n",
    "    med_entities(list): list of ConceptNet nodes linked to med_corpus\n",
    "    \n",
    "    Returns: \n",
    "    bool: True if claim related to public health, otherwise False\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "\n",
    "        claim, entities, index = input_data\n",
    "        print(f\"Index of processed row: {index}.\")\n",
    "\n",
    "        # 1. \n",
    "        if any(med_keyword in [w for w in word_tokenize(claim) if w not in punc] for med_keyword in med_corpus):\n",
    "            # exact keyword match, claims related to public health\n",
    "            print(\"Keyword match successful.\")\n",
    "            return True\n",
    "        \n",
    "        # 2. \n",
    "        cn_entities = []\n",
    "        for entity in entities:\n",
    "            # for entities detected with SciSpacy, get corresponding ConceptNet nodes\n",
    "            for cn_entity in get_conceptnet_entity(entity): \n",
    "                cn_entities.append(cn_entity)\n",
    "                \n",
    "                # 3. \n",
    "                print(f\"Match being checked for the following entity: {cn_entity}\")\n",
    "                if pubhealth_match(cn_entity, pubhealth_topics = medical_entities): \n",
    "                    return True # medical context found in one of the entities, further search not required\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Following error occured while execution of function hasMedicalContext_ConceptNet: {e}.\")\n",
    "\n",
    "    # claim not related to public health, return false\n",
    "    return False\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36eab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_pubhealth_context_multiprocess(df: pd.DataFrame, column_name = \"entities\"):\n",
    "#     num_processes = multiprocessing.cpu_count()\n",
    "    num_processes = 5\n",
    "    \n",
    "    print(f\"Number of processes: {num_processes}\")\n",
    "    pool = multiprocessing.Pool(processes=num_processes)\n",
    "\n",
    "    result = pool.map(hasMedicalContext_ConceptNet, zip(df[\"claim\"], df[column_name], df.index.values))\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622d1122",
   "metadata": {},
   "source": [
    "### (3) Filter claims containing uncertainty indicators e.g. \"might\", \"could\", ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bc5492",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty_corpus = {'perhaps', 'barely', 'maybe', 'probably', 'possibly', 'apparently', \n",
    "                      'sometimes', 'mostly', 'occasionally', 'frequently', 'now and then',\n",
    "                      'suppose', 'guess', 'imagine', \n",
    "                      'may', 'might', 'doubt', 'not sure', 'could', 'doubtful', 'unlikely', 'think', 'not sure', \n",
    "                      'uncertain', 'whether', 'suppose', 'shall', 'should', \n",
    "                      'believe', 'assume', 'imagine', 'presume', \n",
    "                      'approximate', 'approximately', 'debatable', 'potentially', 'theoretically',  \n",
    "                      'many', 'few', 'some', 'much', 'numerous', 'plenty', 'lot', 'lots', 'several', 'little', 'most', 'enough'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc149db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_claim(claim:str, corpus: set) -> bool:\n",
    "    \"\"\"\n",
    "    Returns true if claims has a token matching uncertainty_corpus\n",
    "    \"\"\"\n",
    "    is_match = set(str(claim).lower().strip().split(\" \")).isdisjoint(corpus)\n",
    "    return not is_match \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45704330",
   "metadata": {},
   "source": [
    "### (4) Find \"typical\" table fact claims in PubHealth (get inspiration from TabFact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a574b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_pos_tag(claim: str, tag_filter: str, corpus = {}) -> bool:\n",
    "    \"\"\"\n",
    "    Given a text (claim) and a pos filter e.g. \"JJS\", find out if text contains a token matching this pos filter\n",
    "    \n",
    "    Parameters:\n",
    "    claim (str): text where pos should be searched\n",
    "    tag_filter (str): tag used to filter \n",
    "    \n",
    "    Returns:\n",
    "    bool: True if tag_filter found in claim text else False \n",
    "    \"\"\"\n",
    "    claim_tok = tokenize.word_tokenize(str(claim))\n",
    "    pos_tags = nltk.pos_tag(claim_tok)\n",
    "    filtered_tags = [tag for tag in pos_tags if tag[1]==tag_filter]\n",
    "\n",
    "    if filtered_tags != []:\n",
    "        # minimum one token's POS is equal to 'JJS'\n",
    "        if corpus:\n",
    "            # claim has to include min. one token from 'corpus'\n",
    "            return match_claim(claim, corpus)\n",
    "        else:\n",
    "            # no corpus restriction required, return True \n",
    "            return True\n",
    "    else: \n",
    "        return False \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6b8a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('tagsets')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.help.upenn_tagset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebce945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe for which to execute below code: \n",
    "\n",
    "claims = df.copy() # TODO enter here dataframe\n",
    "print(f\"Total number of entries in dataframe: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b85a936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count and aggregations\n",
    "# \"sum\", \"total\", \"totally\", \"average\"\n",
    "\n",
    "aggregation_keywords = {\"sum\", \"total\", \"totally\", \"average\", \"overall\", \"altogether\", \"entire\", \"whole\", \"range\", \n",
    "                        \"difference\", \"summarization\", \"combine\", \"combined\", \"all\", 'every', 'each'}\n",
    "claims[\"is_aggregation\"] = [match_claim(row[\"claim\"], aggregation_keywords) for index, row in claims.iterrows()]\n",
    "\n",
    "print(f\"Entries with aggregation keyword: \" + str(len(claims[claims[\"is_aggregation\"]==True])))\n",
    "claims[claims[\"is_aggregation\"]==True][\"claim\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04668ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Superlatives adj => NLTK JJS\n",
    "\n",
    "claims[\"has_superlative\"] = [has_pos_tag(row[\"claim\"], \"JJS\") for index, row in claims.iterrows()]\n",
    "\n",
    "print(f\"Entries with superlatives: \" + str(len(claims[claims[\"has_superlative\"]==True])))\n",
    "claims[claims[\"has_superlative\"]==True][\"claim\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5933e807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Superlatives adv => NLTK RBS\n",
    "\n",
    "claims[\"has_superlative_adv\"] = [has_pos_tag(row[\"claim\"], \"RBS\") for index, row in claims.iterrows()]\n",
    "\n",
    "print(f\"Entries with superlatives: \" + str(len(claims[claims[\"has_superlative_adv\"]==True])))\n",
    "claims[claims[\"has_superlative_adv\"]==True][\"claim\"][:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28121008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparatives => NLTK JJR and keyword 'than' in claim text\n",
    "\n",
    "comparatives_corpus = {'than', 'difference', 'gap', 'seperate', 'above', 'below', 'equal', 'equally'}\n",
    "claims[\"has_comparative\"] = [has_pos_tag(row[\"claim\"], \"JJR\", comparatives_corpus) for index, row in claims.iterrows()]\n",
    "\n",
    "print(f\"Entries with comparatives: \" + str(len(claims[claims[\"has_comparative\"]==True])))\n",
    "claims[claims[\"has_comparative\"]==True][\"claim\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beffc20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparatives => NLTK RBR and keyword 'than' in claim text\n",
    "\n",
    "comparatives_corpus = {'than', 'difference', 'gap', 'seperate', 'above', 'below', 'equal', 'equally'}\n",
    "claims[\"has_comparative_adv\"] = [has_pos_tag(row[\"claim\"], \"RBR\", comparatives_corpus) for index, row in claims.iterrows()]\n",
    "\n",
    "print(f\"Entries with comparatives: \" + str(len(claims[claims[\"has_comparative_adv\"]==True])))\n",
    "claims[claims[\"has_comparative_adv\"]==True][\"claim\"][:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502f7566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerals => ?? e.g. 5th, 1994, 11,...\n",
    "\n",
    "claims[\"has_numerals\"] = [has_pos_tag(row[\"claim\"], \"CD\") for index, row in claims.iterrows()]\n",
    "\n",
    "print(f\"Entries with numerals: \" + str(len(claims[claims[\"has_numerals\"]==True])))\n",
    "claims[claims[\"has_numerals\"]==True][\"claim\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1f17c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique e.g. \"only\"\n",
    "\n",
    "unique_keywords = {\"only\", \"single\", \"unique\", \"exclusively\", \"individual\"}\n",
    "claims[\"has_unique_keyword\"] = [match_claim(row[\"claim\"], unique_keywords) for index, row in claims.iterrows()]\n",
    "\n",
    "print(f\"Entries with unique keyword: \" + str(len(claims[claims[\"has_unique_keyword\"]==True])))\n",
    "claims[claims[\"has_unique_keyword\"]==True][\"claim\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815c57f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Majority e.g. \"most of\"\n",
    "\n",
    "majority_keywords = {\"majority\"}\n",
    "claims[\"has_majority_keyword\"] = [match_claim(row[\"claim\"], majority_keywords) for index, row in claims.iterrows()]\n",
    "\n",
    "print(f\"Entries with majority keyword: \" + str(len(claims[claims[\"has_majority_keyword\"]==True])))\n",
    "claims[claims[\"has_majority_keyword\"]==True][\"claim\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492dc749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering claims longer than X tokens\n",
    "\n",
    "punc = set(list(punctuation) + [\"''\", \"``\"])\n",
    "\n",
    "def has_short_text(claim: str): \n",
    "    if claim and len(str(claim))>0 and len([w for w in word_tokenize(str(claim)) if w not in punc])<22:\n",
    "        return True \n",
    "    else:\n",
    "        return False\n",
    "\n",
    "claims[\"has_short_text\"] = [has_short_text(row['claim']) for index, row in claims.iterrows()]\n",
    "print(f\"Entries with short text: \" + str(len(claims[claims[\"has_short_text\"]==True])))\n",
    "\n",
    "claims[claims[\"has_short_text\"]==True][\"claim\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cd3e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 200)\n",
    "pd.set_option('display.min_rows', 150)\n",
    "pd.set_option('display.expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e357918",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = claims[claims[\"has_short_text\"]==False][\"claim\"]\n",
    "x[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fadbeb",
   "metadata": {},
   "source": [
    "### (5) Combine previous steps: final dataset:\n",
    "* only claims related to PubHealth topics\n",
    "* 'is_uncertain' == False\n",
    "* at least one of the remaining bool columns == True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95773bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_data.copy()\n",
    "print(f\"Number of initial entries is: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398a231e",
   "metadata": {},
   "source": [
    "#### 1.) Filter train data for uncertain claims "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eac3399",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"is_uncertain\"] = [match_claim(row[\"claim\"], uncertainty_corpus) for index, row in df.iterrows()]\n",
    "\n",
    "print(\"Number of remaining entries after removing uncertain one's: \")\n",
    "print(len(df[df[\"is_uncertain\"]==False]))\n",
    "\n",
    "df = df[df[\"is_uncertain\"]==False]\n",
    "df.head(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51c9360",
   "metadata": {},
   "source": [
    "#### 2.) Finding \"typical\" table facts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4184739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through code in part \"(4) Find \"typical\" table fact claims in PubHealth (get inspiration from TabFact)\"\n",
    "# and enter claims = desired_df.copy() at top\n",
    "\n",
    "df = claims.copy() # afterwards execute this line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f709cce",
   "metadata": {},
   "source": [
    "#### 3.) Filter train_data to get desired subset for further filtering based on pulic health - relatedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebf842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[(df[\"is_uncertain\"]==False) & \n",
    "            ((df[\"is_aggregation\"]==True) | \n",
    "             (df[\"has_superlative\"]==True) | \n",
    "             (df[\"has_superlative_adv\"]==True) | \n",
    "             (df[\"has_comparative\"]==True) |\n",
    "             (df[\"has_comparative_adv\"]==True) | \n",
    "             (df[\"has_numerals\"]==True) | \n",
    "             (df[\"has_unique_keyword\"]==True) | \n",
    "             (df[\"has_majority_keyword\"]==True))]\n",
    "\n",
    "print(f\"Number of remaining train_data entries after filtering: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febfb1c3",
   "metadata": {},
   "source": [
    "#### 4.) Filter train_data to get only short claims (less than 22 tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb50ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[(df[\"has_short_text\"]==True)]\n",
    "print(f\"Number of remaining train_data entries after filtering: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2907aae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO plot barplot with length of claim text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f06ca8",
   "metadata": {},
   "source": [
    "#### 5.) NER with SciSpacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed09caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"entities\"] = [get_entities(claim) for claim in df[\"claim\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c518560",
   "metadata": {},
   "source": [
    "#### 6.) Filter train data for PubHealth related claims (with corpus & ConcepNet) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e05f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    result = has_pubhealth_context_multiprocess(df, \"entities\")\n",
    "    df[\"health_related\"] = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb1db2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of remaining train_data entries after removing one's not related to public health: \")\n",
    "print(len(df[df[\"health_related\"]==True]))\n",
    "\n",
    "# TODO get subset of train_data\n",
    "df = df[df[\"health_related\"]==True]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472258ab",
   "metadata": {},
   "source": [
    "#### 7.) Filter for true/false entries other labels not relevant \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d1fab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "df = df.loc[(df[\"label\"].isin([\"true\", \"false\"]))].copy()\n",
    "len(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808312e6",
   "metadata": {},
   "source": [
    "#### 8.) Update entries in MongoDB \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed95afd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (7a) set new entity 'relevant' for all documents to False \n",
    "train_col.update_many({}, {'$set': {'relevant_claim': False}})\n",
    "\n",
    "# (7b) set only those to True which are in subset \n",
    "for index, row in df.iterrows():\n",
    "    train_col.update_one({'_id': row[\"_id\"]},\n",
    "                         {'$set': {'relevant_claim': row[\"relevant_claim\"]}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fced4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINALLY SAVE RESULTS\n",
    "\n",
    "today = date.today()\n",
    "path = f\"datasets/{today}_train_subset_claims_filtered_second.pickle\"\n",
    "\n",
    "train_2_health.to_pickle(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeff3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2_health = train_2.loc[(train_2[\"health_related\"]==True)] \n",
    "train_2_non_health = train_2.loc[(train_2[\"health_related\"]==False)]                    \n",
    "\n",
    "print(len(train_2))\n",
    "print(len(train_2_health))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
